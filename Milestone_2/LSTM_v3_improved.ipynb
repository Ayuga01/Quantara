{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LSTM Price Prediction - Improved Version\n",
                "\n",
                "**Changes from original:**\n",
                "- Smaller model architecture to prevent overfitting\n",
                "- Added L2 regularization\n",
                "- Learning rate scheduler\n",
                "- Better early stopping with more patience\n",
                "- Data validation and sanity checks\n",
                "- Fixed evaluation metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "from tensorflow.keras.regularizers import l2\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")\n",
                "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration\n",
                "**Change COIN_NAME and HORIZON to train different models**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ======= CONFIGURATION =======\n",
                "COIN_NAME = \"bitcoin\"  # Options: bitcoin, ethereum, solana, cardano, binancecoin\n",
                "HORIZON = \"1h\"         # Options: 1h, 24h\n",
                "\n",
                "BASE_DIR = \"/Users/ayushgupta/Desktop/ML-Driven-Web-Platform-for-Cryptocurrency-Price-Forecasting_November_Batch-5_2025\"\n",
                "SEQ_PATH = f\"{BASE_DIR}/Milestone_1/data/sequences/{COIN_NAME}/{HORIZON}/\"\n",
                "MODEL_SAVE_PATH = f\"{BASE_DIR}/Milestone_2/models/{COIN_NAME}/{HORIZON}/\"\n",
                "\n",
                "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
                "print(f\"Training: {COIN_NAME} - {HORIZON}\")\n",
                "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load sequences\n",
                "X_train = np.load(SEQ_PATH + \"X_train.npy\")\n",
                "y_train = np.load(SEQ_PATH + \"y_train.npy\")\n",
                "X_val = np.load(SEQ_PATH + \"X_val.npy\")\n",
                "y_val = np.load(SEQ_PATH + \"y_val.npy\")\n",
                "X_test = np.load(SEQ_PATH + \"X_test.npy\")\n",
                "y_test = np.load(SEQ_PATH + \"y_test.npy\")\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"DATA SHAPES\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"X_train: {X_train.shape}\")\n",
                "print(f\"y_train: {y_train.shape}\")\n",
                "print(f\"X_val:   {X_val.shape}\")\n",
                "print(f\"y_val:   {y_val.shape}\")\n",
                "print(f\"X_test:  {X_test.shape}\")\n",
                "print(f\"y_test:  {y_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Validation - Critical Sanity Checks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"DATA VALIDATION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Check for NaN/Inf\n",
                "print(f\"\\nNaN in X_train: {np.isnan(X_train).sum()}\")\n",
                "print(f\"NaN in y_train: {np.isnan(y_train).sum()}\")\n",
                "print(f\"Inf in X_train: {np.isinf(X_train).sum()}\")\n",
                "print(f\"Inf in y_train: {np.isinf(y_train).sum()}\")\n",
                "\n",
                "# Check target distribution\n",
                "print(f\"\\ny_train stats:\")\n",
                "print(f\"  Min:    {y_train.min():.4f}\")\n",
                "print(f\"  Max:    {y_train.max():.4f}\")\n",
                "print(f\"  Mean:   {y_train.mean():.4f}\")\n",
                "print(f\"  Std:    {y_train.std():.4f}\")\n",
                "\n",
                "# Check feature distributions (last timestep)\n",
                "print(f\"\\nX_train feature stats (last timestep):\")\n",
                "feature_names = [\"open\", \"high\", \"low\", \"volume\", \"return_1h\", \"volatility_24h\", \n",
                "                 \"ma_24\", \"ma_168\", \"ma_ratio\", \"vol_change\", \"missing_flag\"]\n",
                "for i, name in enumerate(feature_names):\n",
                "    vals = X_train[:, -1, i]\n",
                "    print(f\"  {name:15s}: min={vals.min():.4f}, max={vals.max():.4f}, mean={vals.mean():.4f}\")\n",
                "\n",
                "# Check if data is properly scaled [0, 1]\n",
                "if X_train.min() < -0.1 or X_train.max() > 1.1:\n",
                "    print(\"\\n⚠️ WARNING: Features may not be properly scaled to [0,1]!\")\n",
                "if y_train.min() < -0.1 or y_train.max() > 1.1:\n",
                "    print(\"⚠️ WARNING: Target may not be properly scaled to [0,1]!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize target distribution\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "axes[0].hist(y_train, bins=50, alpha=0.7, label='Train', color='blue')\n",
                "axes[0].hist(y_val, bins=50, alpha=0.7, label='Val', color='orange')\n",
                "axes[0].set_title('Target Distribution')\n",
                "axes[0].legend()\n",
                "axes[0].set_xlabel('Scaled Price')\n",
                "\n",
                "axes[1].plot(y_train[:1000], linewidth=0.5)\n",
                "axes[1].set_title('y_train (first 1000 samples)')\n",
                "axes[1].set_xlabel('Sample')\n",
                "axes[1].set_ylabel('Scaled Price')\n",
                "\n",
                "axes[2].plot(y_test[:500], linewidth=0.5)\n",
                "axes[2].set_title('y_test (first 500 samples)')\n",
                "axes[2].set_xlabel('Sample')\n",
                "axes[2].set_ylabel('Scaled Price')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build Improved Model\n",
                "\n",
                "**Key changes:**\n",
                "- Smaller architecture (32 → 16 LSTM units instead of 128 → 64)\n",
                "- L2 regularization to prevent overfitting\n",
                "- Batch normalization for stability\n",
                "- Sigmoid output since target is [0, 1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_model(input_shape, l2_reg=0.001):\n",
                "    \"\"\"Build improved LSTM model with regularization.\"\"\"\n",
                "    model = Sequential([\n",
                "        # First LSTM layer - smaller than before\n",
                "        LSTM(32, \n",
                "             return_sequences=True, \n",
                "             input_shape=input_shape,\n",
                "             kernel_regularizer=l2(l2_reg),\n",
                "             recurrent_regularizer=l2(l2_reg)),\n",
                "        BatchNormalization(),\n",
                "        Dropout(0.2),\n",
                "        \n",
                "        # Second LSTM layer\n",
                "        LSTM(16, \n",
                "             kernel_regularizer=l2(l2_reg),\n",
                "             recurrent_regularizer=l2(l2_reg)),\n",
                "        BatchNormalization(),\n",
                "        Dropout(0.2),\n",
                "        \n",
                "        # Dense layers\n",
                "        Dense(8, activation=\"relu\", kernel_regularizer=l2(l2_reg)),\n",
                "        \n",
                "        # Output layer - sigmoid since target is [0, 1]\n",
                "        Dense(1, activation=\"sigmoid\")\n",
                "    ])\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Build model\n",
                "input_shape = (X_train.shape[1], X_train.shape[2])  # (48, 11)\n",
                "model = build_model(input_shape)\n",
                "\n",
                "# Compile with a lower learning rate\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
                "    loss=\"mse\",\n",
                "    metrics=[\"mae\"]\n",
                ")\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup Callbacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks\n",
                "checkpoint = ModelCheckpoint(\n",
                "    f\"{MODEL_SAVE_PATH}/best_lstm_{COIN_NAME}_{HORIZON}.keras\",\n",
                "    monitor=\"val_loss\",\n",
                "    save_best_only=True,\n",
                "    mode=\"min\",\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "early_stop = EarlyStopping(\n",
                "    monitor=\"val_loss\",\n",
                "    patience=20,  # Increased patience\n",
                "    restore_best_weights=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "reduce_lr = ReduceLROnPlateau(\n",
                "    monitor=\"val_loss\",\n",
                "    factor=0.5,\n",
                "    patience=5,\n",
                "    min_lr=1e-6,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "callbacks = [checkpoint, early_stop, reduce_lr]\n",
                "print(\"Callbacks configured:\")\n",
                "print(\"  - ModelCheckpoint (save best)\")\n",
                "print(\"  - EarlyStopping (patience=20)\")\n",
                "print(\"  - ReduceLROnPlateau (factor=0.5, patience=5)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(f\"TRAINING: {COIN_NAME} - {HORIZON}\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_data=(X_val, y_val),\n",
                "    epochs=100,  # More epochs, but early stopping will handle it\n",
                "    batch_size=64,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
                "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
                "axes[0].set_title(f'{COIN_NAME} {HORIZON} - Loss Curve')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('MSE Loss')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# MAE\n",
                "axes[1].plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
                "axes[1].plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
                "axes[1].set_title(f'{COIN_NAME} {HORIZON} - MAE Curve')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('MAE')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{MODEL_SAVE_PATH}/training_curves.png\", dpi=150)\n",
                "plt.show()\n",
                "\n",
                "# Check for overfitting\n",
                "final_train_loss = history.history['loss'][-1]\n",
                "final_val_loss = history.history['val_loss'][-1]\n",
                "overfit_ratio = final_val_loss / final_train_loss\n",
                "\n",
                "print(f\"\\nFinal Train Loss: {final_train_loss:.6f}\")\n",
                "print(f\"Final Val Loss:   {final_val_loss:.6f}\")\n",
                "print(f\"Overfit Ratio:    {overfit_ratio:.2f}x\")\n",
                "\n",
                "if overfit_ratio > 5:\n",
                "    print(\"⚠️ WARNING: Model may be overfitting (val_loss >> train_loss)\")\n",
                "elif overfit_ratio < 2:\n",
                "    print(\"✅ Good: Model seems well-regularized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test set\n",
                "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
                "print(\"=\" * 50)\n",
                "print(\"TEST SET EVALUATION\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Test MSE:  {test_loss:.6f}\")\n",
                "print(f\"Test MAE:  {test_mae:.6f}\")\n",
                "print(f\"Test RMSE: {np.sqrt(test_loss):.6f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions\n",
                "preds = model.predict(X_test, verbose=0).flatten()\n",
                "\n",
                "# Calculate metrics\n",
                "mae = mean_absolute_error(y_test, preds)\n",
                "mse = mean_squared_error(y_test, preds)\n",
                "rmse = np.sqrt(mse)\n",
                "r2 = r2_score(y_test, preds)\n",
                "\n",
                "# MAPE (handle division by zero)\n",
                "mask = y_test > 0.01\n",
                "mape = np.mean(np.abs((y_test[mask] - preds[mask]) / y_test[mask])) * 100\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"DETAILED METRICS (on scaled data)\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"MAE:   {mae:.4f}\")\n",
                "print(f\"RMSE:  {rmse:.4f}\")\n",
                "print(f\"MAPE:  {mape:.2f}%\")\n",
                "print(f\"R²:    {r2:.4f}\")\n",
                "\n",
                "if r2 < 0:\n",
                "    print(\"\\n⚠️ NEGATIVE R² - Model is worse than predicting the mean!\")\n",
                "elif r2 > 0.5:\n",
                "    print(\"\\n✅ Good R² score!\")\n",
                "else:\n",
                "    print(\"\\n⚠️ Low R² - Model has room for improvement\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Baseline comparison: Persistence model (predict last known value)\n",
                "# The last value in the sequence (X[:, -1, :]) contains scaled features\n",
                "# We compare against just predicting y stays the same\n",
                "\n",
                "# Shift y_test by 1 to get \"previous\" value as baseline\n",
                "baseline_preds = np.roll(y_test, 1)\n",
                "baseline_preds[0] = y_test[0]  # Handle first element\n",
                "\n",
                "baseline_mae = mean_absolute_error(y_test, baseline_preds)\n",
                "baseline_r2 = r2_score(y_test, baseline_preds)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"BASELINE COMPARISON\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Persistence Baseline MAE: {baseline_mae:.4f}\")\n",
                "print(f\"Persistence Baseline R²:  {baseline_r2:.4f}\")\n",
                "print(f\"\\nLSTM Model MAE:          {mae:.4f}\")\n",
                "print(f\"LSTM Model R²:           {r2:.4f}\")\n",
                "\n",
                "if mae < baseline_mae:\n",
                "    improvement = (baseline_mae - mae) / baseline_mae * 100\n",
                "    print(f\"\\n✅ Model beats baseline by {improvement:.1f}%!\")\n",
                "else:\n",
                "    print(\"\\n⚠️ Model performs worse than simple persistence baseline\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot predictions vs actual\n",
                "n_samples = 500\n",
                "\n",
                "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
                "\n",
                "# Time series plot\n",
                "axes[0].plot(y_test[:n_samples], label='Actual', linewidth=1.5, alpha=0.8)\n",
                "axes[0].plot(preds[:n_samples], label='Predicted', linewidth=1.5, alpha=0.8)\n",
                "axes[0].set_title(f'{COIN_NAME} {HORIZON} - Predictions vs Actual')\n",
                "axes[0].set_xlabel('Sample')\n",
                "axes[0].set_ylabel('Scaled Price')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Scatter plot\n",
                "axes[1].scatter(y_test, preds, alpha=0.3, s=10)\n",
                "axes[1].plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect Prediction')\n",
                "axes[1].set_title('Predicted vs Actual (Scatter)')\n",
                "axes[1].set_xlabel('Actual')\n",
                "axes[1].set_ylabel('Predicted')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "axes[1].set_xlim(0, 1)\n",
                "axes[1].set_ylim(0, 1)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{MODEL_SAVE_PATH}/predictions.png\", dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the final model\n",
                "final_path = f\"{MODEL_SAVE_PATH}/final_lstm_{COIN_NAME}_{HORIZON}.keras\"\n",
                "model.save(final_path)\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"MODEL SAVED\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Path: {final_path}\")\n",
                "print(f\"\\nFinal Metrics:\")\n",
                "print(f\"  MAE:  {mae:.4f}\")\n",
                "print(f\"  RMSE: {rmse:.4f}\")\n",
                "print(f\"  R²:   {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Quick Test: Verify Model Output Range"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify model outputs are in valid range\n",
                "print(\"=\" * 50)\n",
                "print(\"MODEL OUTPUT VALIDATION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(f\"Prediction range: [{preds.min():.4f}, {preds.max():.4f}]\")\n",
                "print(f\"Expected range:   [0.0000, 1.0000]\")\n",
                "\n",
                "if preds.min() >= 0 and preds.max() <= 1:\n",
                "    print(\"✅ Model outputs are in valid range\")\n",
                "else:\n",
                "    print(\"⚠️ Model outputs are outside [0, 1] range!\")\n",
                "\n",
                "# Check for constant predictions\n",
                "pred_std = preds.std()\n",
                "print(f\"\\nPrediction std: {pred_std:.4f}\")\n",
                "if pred_std < 0.01:\n",
                "    print(\"⚠️ WARNING: Predictions are nearly constant! Model may not have learned.\")\n",
                "else:\n",
                "    print(\"✅ Predictions have good variance\")\n",
                "\n",
                "# Check extreme saturation\n",
                "near_zero = (preds < 0.05).sum() / len(preds) * 100\n",
                "near_one = (preds > 0.95).sum() / len(preds) * 100\n",
                "print(f\"\\nPredictions near 0 (<0.05): {near_zero:.1f}%\")\n",
                "print(f\"Predictions near 1 (>0.95): {near_one:.1f}%\")\n",
                "\n",
                "if near_zero > 50 or near_one > 50:\n",
                "    print(\"⚠️ WARNING: Model is saturating to extreme values!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Next Steps\n",
                "\n",
                "After training all coins, run these cells to train the next coin:\n",
                "\n",
                "1. Change `COIN_NAME` in the Configuration cell\n",
                "2. Restart kernel and run all cells\n",
                "3. Repeat for: `bitcoin`, `ethereum`, `solana`, `cardano`, `binancecoin`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}